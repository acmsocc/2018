wilkes:
  name: 'John Wilkes (Google)'
  title: 'Building the warehouse scale computer'
  abstract: "Imagine some product team inside Google wants 100,000 CPU cores + RAM + flash + accelerators + disk in a couple of months. 
  We need to decide where to put them, when; whether to deploy new machines, or re-purpose/reconfigure old ones; ensure we have 
  enough power, cooling, networking, physical racks, data centers and (over longer a time-frame) wind power; cope with variances 
  in delivery times from supply logistics hiccups; do multi-year cost-optimal placement+decisions in the face of literally 
  thousands of different machine configurations; keep track of parts; schedule repairs, upgrades, and installations; and 
  generally make all this happen behind the scenes at minimum cost. And then we get to dynamically allocate resources 
  (on the small-minutes timescale) to the product groups that need them most urgently, accurately reflecting the cost 
  (opex/capex) of all the machines and infrastructure we just deployed, and monitoring and controlling the datacenter power 
  and cooling systems to achieve minimum overheads - even as we replace all of these on the fly. This talk will highlight some of 
  the exciting problems we're working on inside Google to ensure we can supply the needs of an organization that is experiencing 
  (literally) exponential growth in computing capacity."
  bio1: "John Wilkes has been at Google since 2008, where he is working on automation for building warehouse scale computers. 
  Before that, he spent a long time at HP Labs, becoming an HP and ACM Fellow in 2002.  He is interested in far too many 
  aspects of distributed systems, but a recurring theme has been technologies that allow systems to manage themselves. 
  In his spare time he continues, stubbornly, trying to learn how to blow glass."
  
  
gustavo:
  name: 'Alonso Gustavo  (ETH Zürich)'
  abstract: "Computing Systems are undergoing a multitude of interesting changes: from the platforms (cloud, appliances) to the 
  workloads, data types, and operations (big data, machine learning). Many of these changes are driven or being tackled through 
  innovation in hardware even to the point of having fully specialized designs for particular applications. In this talk I will 
  review some of the most important changes happening in hardware and discuss how they affect system design as well as the 
  opportunities they create. I will focus on data processing as an example but also discuss applications in other areas. 
  I will also briefly discuss how these trends are likely to result in a very different form of IT, and consequently of 
  Computer Science, from the one we know today."
  bio1: "Gustavo Alonso is a Professor of Computer Science at ETH Zürich. He studied telecommunications -electrical engineering- at the 
  Madrid Technical University (ETSIT, Politécnica de Madrid). As a Fulbright scholar, he completed an M.S. and Ph.D. in Computer Science 
  at UC Santa Barbara. After graduating from Santa Barbara, he worked at the IBM Almaden Research Center before joining ETHZ. 
  His research interests encompass almost all aspects of systems, from design to run time. He works on distributed systems, 
  data processing, and system aspects of programming languages. Most of his research these days is related to multi-core architectures, 
  data centers, FPGAs, and hardware acceleration. Gustavo has received numerous awards for his research, including three Test-of-Time 
  awards for work in databases, programming languages, and systems. He is a Fellow of the ACM and of the IEEE."
  title: 'How Hardware Evolution is Driving Software Systems'
  
  
#magda:
 # name: 'Magda Balazinska (University of Washington)'
 # title: 'Performance SLAs for Cloud Data Analytics'
 # abstract: "A variety of data analytics systems are available as cloud services today, including Amazon Elastic MapReduce (EMR), Redshift, Azure's HDInsight, and others. To buy these services, users select and pay for a given cluster configuration: i.e., number and type of service instances. It is well known, however, that users often have difficultly selecting configurations that meet their needs. In this talk, we present our recent work developing the PSLAManager and PerfEnforce systems that together enable users to directly purchase performance levels expressed as runtimes for queries over users' specific datasets.  Given a cloud data analytics service, the PSLAManager generates a database-specific performance-oriented SLA with multiple choices of service tiers. PerfEnforce uses elastic scaling to meet, at a low cost, the SLA runtime guarantees that the user purchases. We present the core algorithms behind each system as well as their evaluation using the Myria cloud data analytics system running on Amazon EC2."
 # bio1: "Magdalena Balazinska is a Professor in the Paul G. Allen School of Computer Science and Engineering at the University of Washington and the Director of the University of Washington eScience Institute. She's also the director of the IGERT PhD Program in Big Data and Data Science and the director of the associated Advanced Data Science PhD Option. Magdalena's research interests are in the field of database management systems. Her current research focuses on data management for data science, big data systems, and cloud computing. Magdalena holds a Ph.D. from the Massachusetts Institute of Technology (2006). She is a Microsoft Research New Faculty Fellow (2007), received the inaugural VLDB Women in Database Research Award (2016), an ACM SIGMOD Test-ofTime Award (2017), an NSF CAREER Award (2009), a 10-year most influential paper award (2010), a Google Research Award (2011), an HP Labs Research Innovation Award (2009 and 2010), a Rogel Faculty Support Award (2006), a Microsoft Research Graduate Fellowship (2003-2005), and multiple best-paper awards."
